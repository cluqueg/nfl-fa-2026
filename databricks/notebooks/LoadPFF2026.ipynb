{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53eeb297-a172-4cef-99b2-001a469a5c3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Cargar Datos de PFF\n",
    "\n",
    "Este notebook se encarga actualizar las tablas con los datos de Pro Football Focus. Tan sólo se ejecuta cuando quieres refrescar los datos de una temporada.\n",
    "\n",
    "### Pre-procesado manual\n",
    "Los datos se extraen manualmente de la web siguiendo este proceso:\n",
    "\n",
    "1. Ve a la web de [PFF](https://premium.pff.com/nfl/positions/2025/REGPO), selecciona una categoría y luego pulsa CSV para descargar un fichero con los datos.\n",
    "2. Desde Catalog, sube el fichero a `/Volumes/nfl-data/pff/2025/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb00f55a-87ab-48c7-bc5c-9bcbe9254d5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Defensa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94999434-aaa7-427d-ada1-0cdf1553b4a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File location and type\n",
    "file_location = \"/Volumes/nfl-data/pff/2025/defense_summary.csv\" \n",
    "file_type = \"csv\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"mergeSchema\", \"true\") \\\n",
    "  .option(\"sep\", \",\") \\\n",
    "  .load(file_location)\n",
    "\n",
    "# Delta Table\n",
    "permanent_table_name = \"defense_summary\"\n",
    "df.write.format(\"delta\").saveAsTable(permanent_table_name, mode=\"overwrite\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f5fef3d-832b-4508-a6c5-d7880633ee57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Ataque - Bloqueo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f07c021f-7a3e-4e7f-aa3d-29878a7b8a54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File location and type\n",
    "file_location = \"/Volumes/nfl-data/pff/2025/offense_blocking.csv\" \n",
    "file_type = \"csv\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"mergeSchema\", \"true\") \\\n",
    "  .option(\"sep\", \",\") \\\n",
    "  .load(file_location)\n",
    "\n",
    "# Delta Table\n",
    "permanent_table_name = \"offense_blocking\"\n",
    "df.write.format(\"delta\").saveAsTable(permanent_table_name, mode=\"overwrite\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7e207b0-6052-4ae5-9be6-3ac07463fff3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Ataque - QB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "654178e8-fa85-4ea2-9592-6083037a611f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File location and type\n",
    "file_location = \"/Volumes/nfl-data/pff/2025/passing_summary.csv\" \n",
    "file_type = \"csv\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"mergeSchema\", \"true\") \\\n",
    "  .option(\"sep\", \",\") \\\n",
    "  .load(file_location)\n",
    "\n",
    "# Delta Table\n",
    "permanent_table_name = \"passing_summary\"\n",
    "df.write.format(\"delta\").saveAsTable(permanent_table_name, mode=\"overwrite\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e18a5076-d85b-4fa4-b8e9-ee5404b52db4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Ataque - Carrera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab271804-67fd-4c1d-ad51-146b7d5ff66a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File location and type\n",
    "file_location = \"/Volumes/nfl-data/pff/2025/rushing_summary.csv\" \n",
    "file_type = \"csv\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"mergeSchema\", \"true\") \\\n",
    "  .option(\"sep\", \",\") \\\n",
    "  .load(file_location)\n",
    "\n",
    "# Delta Table\n",
    "permanent_table_name = \"rushing_summary\"\n",
    "df.write.format(\"delta\").saveAsTable(permanent_table_name, mode=\"overwrite\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63a08a68-ee91-4609-9815-acb9448771d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Ataque - Recepcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94cfb96a-2b14-464c-bdb2-30a0b962754c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File location and type\n",
    "file_location = \"/Volumes/nfl-data/pff/2025/receiving_summary.csv\" \n",
    "file_type = \"csv\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"mergeSchema\", \"true\") \\\n",
    "  .option(\"sep\", \",\") \\\n",
    "  .load(file_location)\n",
    "\n",
    "# Delta Table\n",
    "permanent_table_name = \"receiving_summary\"\n",
    "df.write.format(\"delta\").saveAsTable(permanent_table_name, mode=\"overwrite\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbdba00f-9338-47a1-8d8d-6b33c4c07483",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Equipos Especiales - Retorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c57e6f12-6fd4-4b3a-a4b2-3ecce633c8ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File location and type\n",
    "file_location = \"/Volumes/nfl-data/pff/2025/return_summary.csv\" \n",
    "file_type = \"csv\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"mergeSchema\", \"true\") \\\n",
    "  .option(\"sep\", \",\") \\\n",
    "  .load(file_location)\n",
    "\n",
    "# Delta Table\n",
    "permanent_table_name = \"return_summary\"\n",
    "df.write.format(\"delta\").saveAsTable(permanent_table_name, mode=\"overwrite\")  "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "LoadPFF2026",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
